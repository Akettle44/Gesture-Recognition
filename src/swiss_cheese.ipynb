{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEMO_LENGTH = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QApplication: invalid style override 'adwaita' passed, ignoring it.\n",
      "\tAvailable styles: Windows, Fusion\n"
     ]
    }
   ],
   "source": [
    "#test script for grabbing webcam frames\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for i in range(0, 100):\n",
    "\tres, frame = cap.read()\n",
    "\tif res:\n",
    "\t\tcv2.imshow(\"frame\", frame)\n",
    "\t\tcv2.waitKey(1)\n",
    "\telse:\n",
    "\t\tprint(\"Couldn't grab frame\\n\")\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Setup Google Hands API and initialize the video stream\n",
    "\n",
    "# initialize video stream \n",
    "cap = cv2.VideoCapture(0) #Note, you need a webcam to be plugged in\n",
    "\n",
    "# setup google hands api\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.75, min_tracking_confidence=0.75)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for drawing the landmarks on the screen\n",
    "\n",
    "def drawHands(results, image):\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\tif results.multi_hand_landmarks:\n",
    "\t\tfor hand_landmarks in results.multi_hand_landmarks:\n",
    "\t\t\tmp_drawing.draw_landmarks(\n",
    "\t\t\t\timage,\n",
    "\t\t\t\thand_landmarks,\n",
    "\t\t\t\tmp_hands.HAND_CONNECTIONS,\n",
    "\t\t\t\tmp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "\t\t\t\tmp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "\t\tretval = 0\n",
    "\telse:\n",
    "\t\tretval = -1\n",
    "\n",
    "\treturn retval, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo capturing landmarks\n",
    "landmark_list = []\n",
    "\n",
    "for i in range(0, DEMO_LENGTH):\n",
    "\tres, frame = cap.read()\n",
    "\tif not res:\n",
    "\t\tprint(\"Couldn't grab frame, continuing to next iteration\")\n",
    "\telse:\n",
    "\t\t# Convert to RGB (opencv is natively BGR)\n",
    "\t\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\t\t# Get hand landmarks \n",
    "\t\tresults = hands.process(frame)\n",
    "\t\t# Show landmarks superimposed on hand\n",
    "\t\tstat, image = drawHands(results, frame)\n",
    "\t\tif stat != 0:\n",
    "\t\t\tprint(\"Didn't detect hand\")\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\tlandmark_list.append(results)\n",
    "\t\t\tcv2.imshow(\"Landmarks\", cv2.flip(image, 1))\n",
    "\t\t\tif cv2.waitKey(5) & 0xFF == 27:\n",
    "\t\t\t\t# Exit demo\n",
    "\t\t\t\tbreak\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring results variable\n",
    "\n",
    "print(landmark_list[0].multi_hand_landmarks)\n",
    "print(len(landmark_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create tabular data given landmarks\n",
    "\n",
    "def tabulate_training(class_name, landmark_list):\n",
    "\toutput = pd.DataFrame()\n",
    "\tfor res in landmark_list:\n",
    "\t\tfor lms in res.multi_hand_landmarks:\n",
    "\t\t\tmap = {\"class\" : class_name}\n",
    "\t\t\tfor id, lm in enumerate(lms.landmark):\n",
    "\t\t\t\tmap.update({f\"x{id}\": lm.x, f\"y{id}\": lm.y, f\"z{id}\": lm.z})\n",
    "\t\t\toutput = output.append(map, ignore_index=True)\n",
    "\treturn output\n",
    "\n",
    "def tabulate_test(landmark_list):\n",
    "\toutput = pd.DataFrame()\n",
    "\tfor lms in landmark_list.multi_hand_landmarks:\n",
    "\t\tmap = {}\n",
    "\t\tfor id, lm in enumerate(lms.landmark):\n",
    "\t\t\tmap.update({f\"x{id}\": lm.x, f\"y{id}\": lm.y, f\"z{id}\": lm.z})\n",
    "\t\toutput = output.append(map, ignore_index=True)\n",
    "\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>z0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>...</th>\n",
       "      <th>z17</th>\n",
       "      <th>x18</th>\n",
       "      <th>y18</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stop</td>\n",
       "      <td>0.252260</td>\n",
       "      <td>0.741342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333063</td>\n",
       "      <td>0.721361</td>\n",
       "      <td>-0.038322</td>\n",
       "      <td>0.393355</td>\n",
       "      <td>0.652485</td>\n",
       "      <td>-0.070456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124288</td>\n",
       "      <td>0.153720</td>\n",
       "      <td>0.514585</td>\n",
       "      <td>-0.167335</td>\n",
       "      <td>0.144373</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>-0.186584</td>\n",
       "      <td>0.139733</td>\n",
       "      <td>0.397697</td>\n",
       "      <td>-0.199893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stop</td>\n",
       "      <td>0.254086</td>\n",
       "      <td>0.740715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339084</td>\n",
       "      <td>0.700779</td>\n",
       "      <td>-0.028755</td>\n",
       "      <td>0.402925</td>\n",
       "      <td>0.624416</td>\n",
       "      <td>-0.051615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095957</td>\n",
       "      <td>0.145521</td>\n",
       "      <td>0.470683</td>\n",
       "      <td>-0.129994</td>\n",
       "      <td>0.129839</td>\n",
       "      <td>0.408852</td>\n",
       "      <td>-0.147285</td>\n",
       "      <td>0.121764</td>\n",
       "      <td>0.350553</td>\n",
       "      <td>-0.159227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stop</td>\n",
       "      <td>0.259596</td>\n",
       "      <td>0.734767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345050</td>\n",
       "      <td>0.688579</td>\n",
       "      <td>-0.027602</td>\n",
       "      <td>0.410532</td>\n",
       "      <td>0.606795</td>\n",
       "      <td>-0.047735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090573</td>\n",
       "      <td>0.143592</td>\n",
       "      <td>0.443679</td>\n",
       "      <td>-0.123582</td>\n",
       "      <td>0.125729</td>\n",
       "      <td>0.383944</td>\n",
       "      <td>-0.140936</td>\n",
       "      <td>0.115205</td>\n",
       "      <td>0.327756</td>\n",
       "      <td>-0.152640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stop</td>\n",
       "      <td>0.259695</td>\n",
       "      <td>0.720178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348577</td>\n",
       "      <td>0.677222</td>\n",
       "      <td>-0.032187</td>\n",
       "      <td>0.415211</td>\n",
       "      <td>0.593063</td>\n",
       "      <td>-0.053567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092355</td>\n",
       "      <td>0.140997</td>\n",
       "      <td>0.421667</td>\n",
       "      <td>-0.127465</td>\n",
       "      <td>0.121394</td>\n",
       "      <td>0.361382</td>\n",
       "      <td>-0.146220</td>\n",
       "      <td>0.108424</td>\n",
       "      <td>0.304768</td>\n",
       "      <td>-0.158666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop</td>\n",
       "      <td>0.272157</td>\n",
       "      <td>0.710538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359213</td>\n",
       "      <td>0.666697</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>0.424839</td>\n",
       "      <td>0.579234</td>\n",
       "      <td>-0.058048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096894</td>\n",
       "      <td>0.143589</td>\n",
       "      <td>0.407690</td>\n",
       "      <td>-0.133802</td>\n",
       "      <td>0.122728</td>\n",
       "      <td>0.346034</td>\n",
       "      <td>-0.154512</td>\n",
       "      <td>0.108510</td>\n",
       "      <td>0.288053</td>\n",
       "      <td>-0.168556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class        x0        y0   z0        x1        y1        z1        x2  \\\n",
       "0  stop  0.252260  0.741342  0.0  0.333063  0.721361 -0.038322  0.393355   \n",
       "1  stop  0.254086  0.740715  0.0  0.339084  0.700779 -0.028755  0.402925   \n",
       "2  stop  0.259596  0.734767  0.0  0.345050  0.688579 -0.027602  0.410532   \n",
       "3  stop  0.259695  0.720178  0.0  0.348577  0.677222 -0.032187  0.415211   \n",
       "4  stop  0.272157  0.710538  0.0  0.359213  0.666697 -0.035065  0.424839   \n",
       "\n",
       "         y2        z2  ...       z17       x18       y18       z18       x19  \\\n",
       "0  0.652485 -0.070456  ... -0.124288  0.153720  0.514585 -0.167335  0.144373   \n",
       "1  0.624416 -0.051615  ... -0.095957  0.145521  0.470683 -0.129994  0.129839   \n",
       "2  0.606795 -0.047735  ... -0.090573  0.143592  0.443679 -0.123582  0.125729   \n",
       "3  0.593063 -0.053567  ... -0.092355  0.140997  0.421667 -0.127465  0.121394   \n",
       "4  0.579234 -0.058048  ... -0.096894  0.143589  0.407690 -0.133802  0.122728   \n",
       "\n",
       "        y19       z19       x20       y20       z20  \n",
       "0  0.453468 -0.186584  0.139733  0.397697 -0.199893  \n",
       "1  0.408852 -0.147285  0.121764  0.350553 -0.159227  \n",
       "2  0.383944 -0.140936  0.115205  0.327756 -0.152640  \n",
       "3  0.361382 -0.146220  0.108424  0.304768 -0.158666  \n",
       "4  0.346034 -0.154512  0.108510  0.288053 -0.168556  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data tabulation\n",
    "\n",
    "df = tabulate_training(\"stop\")\n",
    "df.keys()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture training data for a particular class\n",
    "def capture_training_data():\n",
    "\tlandmark_list = []\n",
    "\tfor i in range(0, DEMO_LENGTH):\n",
    "\t\tres, frame = cap.read()\n",
    "\t\tif not res:\n",
    "\t\t\tprint(\"Couldn't grab frame, continuing to next iteration\")\n",
    "\t\telse:\n",
    "\t\t\t# Convert to RGB (opencv is natively BGR)\n",
    "\t\t\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\t\t\t# Get hand landmarks \n",
    "\t\t\tresults = hands.process(frame)\n",
    "\t\t\t# Show landmarks superimposed on hand\n",
    "\t\t\tstat, image = drawHands(results, frame)\n",
    "\t\t\tif stat != 0:\n",
    "\t\t\t\t#print(\"Didn't detect hand\")\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telse:\n",
    "\t\t\t\tlandmark_list.append(results)\n",
    "\t\t\t\tcv2.imshow(\"Landmarks\", cv2.flip(image, 1))\n",
    "\t\t\t\tif cv2.waitKey(5) & 0xFF == 27:\n",
    "\t\t\t\t\t# Exit demo\n",
    "\t\t\t\t\tbreak\n",
    "\tcv2.destroyAllWindows()\n",
    "\treturn landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect training data for stop command\n",
    "stop_landmark_list = capture_training_data()\n",
    "stp_df = tabulate_training(\"stop\", stop_landmark_list)\n",
    "stp_df.head()\n",
    "stp_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect training data for scroll down\n",
    "scroll_down_landmark_list = capture_training_data()\n",
    "scr_dwn_df = tabulate_training(\"scroll_down\", scroll_down_landmark_list)\n",
    "scr_dwn_df.head()\n",
    "scr_dwn_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect training data for scroll up\n",
    "scroll_up_landmark_list = capture_training_data()\n",
    "scr_up_df = tabulate_training(\"scroll_up\", scroll_up_landmark_list)\n",
    "scr_up_df.head()\n",
    "scr_up_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect training data for window right\n",
    "wnd_right_landmark_list = capture_training_data()\n",
    "wnd_right_df = tabulate_training(\"window_right\", wnd_right_landmark_list)\n",
    "wnd_right_df.head()\n",
    "wnd_right_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect training data for turn off pc\n",
    "power_off_landmark_list = capture_training_data()\n",
    "power_off_df = tabulate_training(\"power_off\", power_off_landmark_list)\n",
    "power_off_df.head()\n",
    "power_off_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done grabbing training data, clean up capture\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stich dataframes together and write to csv\n",
    "\n",
    "overall_df = pd.DataFrame()\n",
    "overall_df = overall_df.append(stp_df, ignore_index=True)\n",
    "overall_df = overall_df.append(scr_dwn_df, ignore_index=True)\n",
    "overall_df = overall_df.append(scr_up_df, ignore_index=True)\n",
    "overall_df = overall_df.append(wnd_right_df, ignore_index=True)\n",
    "overall_df = overall_df.append(power_off_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check overall dataframe properties\n",
    "\n",
    "overall_df.shape[0]\n",
    "overall_df.head()\n",
    "overall_df.tail()\n",
    "\n",
    "# Sanity check\n",
    "print((stp_df.shape[0] + scr_dwn_df.shape[0] + scr_up_df.shape[0] + wnd_right_df.shape[0] + power_off_df.shape[0]) == overall_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write training data to csv\n",
    "overall_df.to_csv(\"../data/training.csv\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for tabular model\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "import sys\n",
    "import pickle as pkl\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training data\n",
    "training_df = pd.read_csv(\"../data/training.csv\")\n",
    "\n",
    "# Drop extra rows names (from incorrect overall_df writing)\n",
    "training_df = training_df.drop(training_df.columns[[0]], axis=1)\n",
    "\n",
    "# Isolate labels\n",
    "labels = training_df['class']\n",
    "training_df = training_df.drop('class', axis=1)\n",
    "\n",
    "#split data for training and testing --> 60% training, 20% validation, 20% test\n",
    "f_train, f_test, l_train, l_test = train_test_split(training_df, labels, test_size=.4, random_state=21)\n",
    "f_val, f_test, l_val, l_test = train_test_split(training_df, labels, test_size=.4, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "boost = GradientBoostingClassifier()\n",
    "hgb = HistGradientBoostingClassifier()\n",
    "\n",
    "algorithms = {'lrg':lrg, 'rf':rf, 'boost':boost, 'hgb':hgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing function for scores and metrics\n",
    "def algo_results(results):\n",
    "\tmts = results.cv_results_['mean_test_score'] #avg score\n",
    "\ttol = results.cv_results_['std_test_score']  #toleranc\n",
    "\toptimal = results.best_params_\n",
    "\tprint('Best parameters: {}'.format(optimal))\n",
    "\tfor mean, std, params in zip(mts, tol, results.cv_results_['params']):\n",
    "\t\tprint(\"%0.3f (+/-%0.3f) for %r\" % (mean, std*2, params))\n",
    "\n",
    "### Algorithm portion ###\n",
    "def train_algo(algo, parameters):\n",
    "\tcv = GridSearchCV(estimator=algorithms[algo], param_grid=parameters, cv=5, scoring='f1_weighted', refit=True)\n",
    "\tcv.fit(f_train, l_train.values.ravel())\n",
    "\tresults=open('../data/{}output.txt'.format(algo), 'w')\n",
    "\tsys.stdout = results\n",
    "\talgo_results(cv) \n",
    "\tpkl_file=open('../pkl/{}pickle.pkl'.format(algo), 'wb')\n",
    "\tpkl.dump(cv.best_estimator_, pkl_file)\n",
    "\tresults.close()\n",
    "\tpkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Models\n",
    "\n",
    "# Logistic Regression\n",
    "c_list = [10, 100] #C = .01 and C performed best (.872)-> High regularization \n",
    "parameters = { 'C':c_list}\n",
    "train_algo('lrg', parameters)\n",
    "\n",
    "# Random Forest\n",
    "n_estimators = [6, 8]\n",
    "max_depth = [16, 22, 36]\n",
    "parameters={'n_estimators':n_estimators, 'max_depth':max_depth}\n",
    "train_algo('rf', parameters)\n",
    "\n",
    "#Gradient Boosted Trees\n",
    "n_estimators = [8, 10]\n",
    "max_depth = [9, 10]\n",
    "learning_rate = [1]\n",
    "parameters={'n_estimators':n_estimators, 'max_depth':max_depth, 'learning_rate':learning_rate}\n",
    "train_algo('boost', parameters)\n",
    "\n",
    "#Histogram Gradient Boosting classifier\n",
    "max_depth = [6, 10, 26]\n",
    "learning_rate = [0.1]\n",
    "parameters={'max_depth':max_depth, 'learning_rate':learning_rate}\n",
    "train_algo('hgb', parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_names = ['rf', 'boost', 'hgb']\n",
    "algo_pkl = {}\n",
    "\n",
    "for name in complex_names: #get pkl objects\n",
    "\tpklfile = open('../pkl/{}pickle.pkl'.format(name), 'rb') #opens pickle and stores it in an array  \n",
    "\talgo_pkl[name] = pkl.load(pklfile)\n",
    "\tpklfile.close()\n",
    "\n",
    "\n",
    "def complex_algo_analysis():\n",
    "    prec = {}\n",
    "    reca = {}\n",
    "    for name in complex_names:\n",
    "        prob = algo_pkl[name].predict_proba(f_val)[:,1]\n",
    "        precision, recall, _ = precision_recall_curve(l_val, prob)\n",
    "        prec[name] = precision\n",
    "        reca[name] = recall\n",
    "    return prec, reca \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for rf\n",
      "1.0\n",
      "1.0\n",
      "Score for boost\n",
      "1.0\n",
      "1.0\n",
      "Score for hgb\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#validation set\n",
    "for name in complex_names:\n",
    "    print(\"Score for {}\".format(name)) #assigning test score\n",
    "    prediction = algo_pkl[name].predict(f_val)\n",
    "    print(accuracy_score(l_val, prediction))\n",
    "    print(f1_score(l_val, prediction, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for rf\n",
      "0.9938775510204082\n",
      "0.9938867790267809\n",
      "Score for boost\n",
      "0.9877551020408163\n",
      "0.9877964761680325\n",
      "Score for hgb\n",
      "0.9948979591836735\n",
      "0.9949027577377876\n"
     ]
    }
   ],
   "source": [
    "# test algo\n",
    "for name in complex_names:\n",
    "    print(\"Score for {}\".format(name)) #assigning test score\n",
    "    prediction = algo_pkl[name].predict(f_test)\n",
    "    print(accuracy_score(l_test, prediction))\n",
    "    print(f1_score(l_test, prediction, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test overall flow and superimpose predicition with confidence score\n",
    "\n",
    "for i in range(0, DEMO_LENGTH):\n",
    "\tres, frame = cap.read()\n",
    "\tif not res:\n",
    "\t\tprint(\"Couldn't grab frame, continuing to next iteration\")\n",
    "\telse:\n",
    "\t\t# Convert to RGB (opencv is natively BGR)\n",
    "\t\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\t\t# Get hand landmarks \n",
    "\t\tresults = hands.process(frame)\n",
    "\t\t# Show landmarks superimposed on hand\n",
    "\t\tstat, image = drawHands(results, frame)\n",
    "\t\tif stat != 0:\n",
    "\t\t\tprint(\"Didn't detect hand\")\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\ttab = tabulate_test(results)\n",
    "\t\t\tpred = algo_pkl['hgb'].predict(tab)\n",
    "\t\t\timage = cv2.flip(image, 1)\n",
    "\t\t\timage = cv2.putText(image, pred[0], (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\t\t\tcv2.imshow(\"Landmarks\", image)\n",
    "\t\t\tif cv2.waitKey(5) & 0xFF == 27:\n",
    "\t\t\t\t# Exit demo\n",
    "\t\t\t\tbreak\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75074364eeccacbc1419af69b995c7da782b829a2c4dcc5281dcf4acc66d3fe6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('swiss': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
